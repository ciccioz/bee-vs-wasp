{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bee_vs_wasp.ipynb","provenance":[],"mount_file_id":"1cEbIBRIzLOBkKDlX7mn0SVHmKP-6ruDl","authorship_tag":"ABX9TyOkyox0cOef8FND4+Ra9JPq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QMbsJs845wti","executionInfo":{"status":"ok","timestamp":1609015612439,"user_tz":-60,"elapsed":624,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}}},"source":["import os, shutil\n","import random\n","\n","from keras import layers\n","from keras import models\n","from keras import optimizers\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras import Model\n","\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import Xception"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGjbAIu54a6C","executionInfo":{"status":"ok","timestamp":1609008918223,"user_tz":-60,"elapsed":640,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}}},"source":["cwd_dir = \"./drive/MyDrive/Python Code/kaggle_bee_vs_wasp\"\n","# os.chdir(cwd_dir)\n","\n","\n","train_dir = os.path.join(cwd_dir, 'data', 'train')\n","val_dir = os.path.join(cwd_dir, 'data', 'validation')\n","test_dir = os.path.join(cwd_dir, 'data', 'test')\n","# os.mkdir(train_dir)\n","# os.mkdir(val_dir)\n","# os.mkdir(test_dir)\n","\n","# train_bee_dir = os.path.join(train_dir, 'bee')\n","# train_wasp_dir = os.path.join(train_dir, 'wasp')\n","# train_insect_dir = os.path.join(train_dir, 'insect')\n","# train_other_dir = os.path.join(train_dir, 'other')\n","# os.mkdir(train_bee_dir)\n","# os.mkdir(train_wasp_dir)\n","# os.mkdir(train_insect_dir)\n","# os.mkdir(train_other_dir)\n","\n","# val_bee_dir = os.path.join(val_dir, 'bee')\n","# val_wasp_dir = os.path.join(val_dir, 'wasp')\n","# val_insect_dir = os.path.join(val_dir, 'insect')\n","# val_other_dir = os.path.join(val_dir, 'other')\n","# os.mkdir(val_bee_dir)\n","# os.mkdir(val_wasp_dir)\n","# os.mkdir(val_insect_dir)\n","# os.mkdir(val_other_dir)\n","\n","# test_bee_dir = os.path.join(test_dir, 'bee')\n","# test_wasp_dir = os.path.join(test_dir, 'wasp')\n","# test_insect_dir = os.path.join(test_dir, 'insect')\n","# test_other_dir = os.path.join(test_dir, 'other')\n","# os.mkdir(test_bee_dir)\n","# os.mkdir(test_wasp_dir)\n","# os.mkdir(test_insect_dir)\n","# os.mkdir(test_other_dir)\n","\n","# dict_folders = {'bee' : 'bee1', 'wasp' : 'wasp1', 'insect' : 'other_insect', 'other' : 'other_noinsect'}\n","\n","# random.seed(1234)\n","# for i in range(0, len(dict_folders)):\n","#   src_folder_chosen = list(dict_folders.values())[i]\n","#   src_path_chosen = os.path.join(cwd_dir, src_folder_chosen)\n","#   dst_folder_chosen = list(dict_folders.keys())[i]\n","#   # dst_path_chosen = os.path.join(dst_folder_chosen)\n","\n","#   file_names = [f for f in os.listdir(src_path_chosen) if os.path.isfile(os.path.join(src_path_chosen, f))]\n","#   for file_name in file_names:\n","#     src = os.path.join(src_path_chosen, file_name)\n","#     n_random = random.uniform(0, 1)\n","#     if n_random < 0.65:\n","#       dst = os.path.join(train_dir, dst_folder_chosen, file_name)\n","#     elif n_random < 0.85:\n","#       dst = os.path.join(val_dir, dst_folder_chosen, file_name)\n","#     elif n_random <= 1:\n","#       dst = os.path.join(test_dir, dst_folder_chosen, file_name)\n","#     shutil.copyfile(src, dst)\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"AE6xJxymQfJI","executionInfo":{"status":"ok","timestamp":1609008921729,"user_tz":-60,"elapsed":752,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}}},"source":["SHAPE = 224\n","BATCH_SIZE = 16"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"hU8da2AnHDmR","executionInfo":{"status":"ok","timestamp":1609008931274,"user_tz":-60,"elapsed":7775,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}}},"source":["# model from scratch\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (SHAPE, SHAPE, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation = 'relu'))\n","model.add(layers.Dense(4, activation = 'softmax'))\n","\n","model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.RMSprop(lr = 0.00001), metrics = ['acc'])\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', patience = 4, verbose = 1)\n","\n","history = model.fit_generator(\n","    train_generator,\n","    epochs = 30,\n","    callbacks = earlystop,\n","    validation_data = valid_generator\n",")\n","# Save our model for inference\n","# model.save(\"model-weights/xception.h5\")\n","model.save(\"primo.h5\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKnXs1K2QGr3","executionInfo":{"status":"ok","timestamp":1609009032487,"user_tz":-60,"elapsed":11174,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}},"outputId":"b6130cdd-97ae-423f-ac2b-36fd8878b362"},"source":["train_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    rotation_range = 15,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    horizontal_flip = True\n",")\n","valid_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    rotation_range = 0,\n","    width_shift_range = 0.0,\n","    height_shift_range = 0.0,\n","    horizontal_flip = False\n",")\n","train_generator = train_datagen.flow_from_directory(\n","    os.path.join(cwd_dir, 'data', 'train/'),\n","    target_size = (SHAPE, SHAPE),\n","    shuffle = True,\n","    batch_size = BATCH_SIZE,\n","    class_mode = 'categorical',\n",")\n","valid_generator = valid_datagen.flow_from_directory(\n","    os.path.join(cwd_dir, 'data', 'validation/'),\n","    target_size = (SHAPE, SHAPE),\n","    shuffle = True,\n","    batch_size = BATCH_SIZE,\n","    class_mode = 'categorical',\n",")\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 5126 images belonging to 4 classes.\n","Found 1562 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dChStN1Yv6-c","executionInfo":{"status":"ok","timestamp":1609018059347,"user_tz":-60,"elapsed":137658,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}},"outputId":"f122149f-f270-46bc-c0e7-caddc884b501"},"source":["# pre-trained model\n","model = Xception(input_shape = (SHAPE, SHAPE, 3), include_top = False, weights = 'imagenet')\n","\n","x = model.output\n","x = layers.AveragePooling2D(pool_size = (2, 2))(x)\n","x = layers.Dense(32, activation = 'relu')(x)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(4, activation = 'softmax', kernel_regularizer = l2(.0005))(x)\n","model = Model(inputs = model.inputs, outputs = x)\n","opt = optimizers.SGD(lr = 0.0001, momentum = .9)\n","model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', patience = 4, verbose = 1)\n","checkpoint = ModelCheckpoint(\n","    os.path.join(cwd_dir, \"model-weights/xception_checkpoint.h5\"),\n","    monitor = \"val_loss\",\n","    mode = \"min\",\n","    save_best_only = True,\n","    verbose = 1\n",")\n","\n","history = model.fit_generator(\n","    train_generator,\n","    epochs = 20,\n","    callbacks = [earlystop, checkpoint],\n","    validation_data = valid_generator\n",")\n","# Save our model for inference\n","model.save(os.path.join(cwd_dir, \"model-weights/xception.h5\"), save_format = 'h5')\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","321/321 [==============================] - 114s 341ms/step - loss: 1.2803 - accuracy: 0.3997 - val_loss: 0.8384 - val_accuracy: 0.6588\n","\n","Epoch 00001: val_loss improved from inf to 0.83839, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 2/20\n","321/321 [==============================] - 111s 345ms/step - loss: 0.8414 - accuracy: 0.6684 - val_loss: 0.6295 - val_accuracy: 0.7465\n","\n","Epoch 00002: val_loss improved from 0.83839 to 0.62948, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 3/20\n","321/321 [==============================] - 112s 347ms/step - loss: 0.6743 - accuracy: 0.7429 - val_loss: 0.5260 - val_accuracy: 0.8035\n","\n","Epoch 00003: val_loss improved from 0.62948 to 0.52595, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 4/20\n","321/321 [==============================] - 112s 347ms/step - loss: 0.5829 - accuracy: 0.7717 - val_loss: 0.4506 - val_accuracy: 0.8502\n","\n","Epoch 00004: val_loss improved from 0.52595 to 0.45063, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 5/20\n","321/321 [==============================] - 111s 346ms/step - loss: 0.5037 - accuracy: 0.8210 - val_loss: 0.4000 - val_accuracy: 0.8752\n","\n","Epoch 00005: val_loss improved from 0.45063 to 0.40002, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 6/20\n","321/321 [==============================] - 112s 347ms/step - loss: 0.4341 - accuracy: 0.8506 - val_loss: 0.3587 - val_accuracy: 0.8828\n","\n","Epoch 00006: val_loss improved from 0.40002 to 0.35869, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 7/20\n","321/321 [==============================] - 114s 354ms/step - loss: 0.4250 - accuracy: 0.8541 - val_loss: 0.3334 - val_accuracy: 0.8854\n","\n","Epoch 00007: val_loss improved from 0.35869 to 0.33343, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 8/20\n","321/321 [==============================] - 112s 348ms/step - loss: 0.3612 - accuracy: 0.8837 - val_loss: 0.3115 - val_accuracy: 0.8950\n","\n","Epoch 00008: val_loss improved from 0.33343 to 0.31154, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 9/20\n","321/321 [==============================] - 113s 349ms/step - loss: 0.3284 - accuracy: 0.8891 - val_loss: 0.2966 - val_accuracy: 0.8982\n","\n","Epoch 00009: val_loss improved from 0.31154 to 0.29662, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 10/20\n","321/321 [==============================] - 112s 348ms/step - loss: 0.3508 - accuracy: 0.8799 - val_loss: 0.2827 - val_accuracy: 0.9027\n","\n","Epoch 00010: val_loss improved from 0.29662 to 0.28270, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 11/20\n","321/321 [==============================] - 113s 350ms/step - loss: 0.2926 - accuracy: 0.9072 - val_loss: 0.2751 - val_accuracy: 0.9020\n","\n","Epoch 00011: val_loss improved from 0.28270 to 0.27512, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 12/20\n","321/321 [==============================] - 112s 349ms/step - loss: 0.2900 - accuracy: 0.8951 - val_loss: 0.2682 - val_accuracy: 0.9072\n","\n","Epoch 00012: val_loss improved from 0.27512 to 0.26823, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 13/20\n","321/321 [==============================] - 112s 349ms/step - loss: 0.2850 - accuracy: 0.8939 - val_loss: 0.2638 - val_accuracy: 0.9142\n","\n","Epoch 00013: val_loss improved from 0.26823 to 0.26382, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 14/20\n","321/321 [==============================] - 113s 350ms/step - loss: 0.2664 - accuracy: 0.9065 - val_loss: 0.2568 - val_accuracy: 0.9155\n","\n","Epoch 00014: val_loss improved from 0.26382 to 0.25679, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 15/20\n","321/321 [==============================] - 112s 349ms/step - loss: 0.2579 - accuracy: 0.9141 - val_loss: 0.2502 - val_accuracy: 0.9149\n","\n","Epoch 00015: val_loss improved from 0.25679 to 0.25022, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 16/20\n","321/321 [==============================] - 111s 346ms/step - loss: 0.2462 - accuracy: 0.9172 - val_loss: 0.2480 - val_accuracy: 0.9200\n","\n","Epoch 00016: val_loss improved from 0.25022 to 0.24804, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 17/20\n","321/321 [==============================] - 112s 348ms/step - loss: 0.2249 - accuracy: 0.9191 - val_loss: 0.2440 - val_accuracy: 0.9174\n","\n","Epoch 00017: val_loss improved from 0.24804 to 0.24401, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 18/20\n","321/321 [==============================] - 113s 349ms/step - loss: 0.2543 - accuracy: 0.9091 - val_loss: 0.2466 - val_accuracy: 0.9142\n","\n","Epoch 00018: val_loss did not improve from 0.24401\n","Epoch 19/20\n","321/321 [==============================] - 113s 351ms/step - loss: 0.2397 - accuracy: 0.9223 - val_loss: 0.2398 - val_accuracy: 0.9213\n","\n","Epoch 00019: val_loss improved from 0.24401 to 0.23983, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n","Epoch 20/20\n","321/321 [==============================] - 112s 348ms/step - loss: 0.2155 - accuracy: 0.9220 - val_loss: 0.2393 - val_accuracy: 0.9200\n","\n","Epoch 00020: val_loss improved from 0.23983 to 0.23935, saving model to ./drive/MyDrive/Python Code/kaggle_bee_vs_wasp/model-weights/xception_checkpoint.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kc7AmOPTb_-K","executionInfo":{"status":"ok","timestamp":1609026268058,"user_tz":-60,"elapsed":2414,"user":{"displayName":"Gianluca Calzati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiabWJbnq3e8vmZ5xPnV0Jb9p2V7RZToZvC6j3miQ=s64","userId":"12560227411956878984"}}},"source":["model.save(os.path.join(cwd_dir, \"model-weights/xception.h5\"), save_format = 'h5')"],"execution_count":17,"outputs":[]}]}