{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bee_vs_wasp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbR5LpxOsi_u"
      },
      "source": [
        "# get data from this link: https://www.kaggle.com/jerzydziewierz/bee-vs-wasp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMbsJs845wti"
      },
      "source": [
        "#### import libraries ####\n",
        "import os, shutil\n",
        "import random\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import Xception"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45t3Em8YpEnW"
      },
      "source": [
        "# some parameters\r\n",
        "flag_create_dataset = False\r\n",
        "SHAPE = 224\r\n",
        "BATCH_SIZE = 64\r\n",
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGjbAIu54a6C"
      },
      "source": [
        "#### dataset creation (compatible with tensorflow) ####\n",
        "\n",
        "# this is the path where I have put folders from Kaggle project\n",
        "cwd_dir = \"./drive/MyDrive/Python Code/kaggle_bee_vs_wasp\"\n",
        "# os.chdir(cwd_dir)\n",
        "\n",
        "train_dir = os.path.join(cwd_dir, 'data', 'train')\n",
        "val_dir = os.path.join(cwd_dir, 'data', 'validation')\n",
        "test_dir = os.path.join(cwd_dir, 'data', 'test')\n",
        "\n",
        "# if True, create dataset\n",
        "if flag_create_dataset == True:\n",
        "  # create directories\n",
        "  os.mkdir(train_dir)\n",
        "  os.mkdir(val_dir)\n",
        "  os.mkdir(test_dir)\n",
        "\n",
        "  # create a directory for each class (bee-wasp-insect-other)\n",
        "  directories = [train_dir, val_dir, test_dir]\n",
        "  for dir in directories:\n",
        "    os.mkdir(os.path.join(dir, 'bee'))\n",
        "    os.mkdir(os.path.join(dir, 'wasp'))\n",
        "    os.mkdir(os.path.join(dir, 'insect'))\n",
        "    os.mkdir(os.path.join(dir, 'other'))\n",
        "\n",
        "  dict_folders = {'bee' : 'bee1', 'wasp' : 'wasp1', 'insect' : 'other_insect', 'other' : 'other_noinsect'}\n",
        "\n",
        "  random.seed(1234)\n",
        "  for i in range(0, len(dict_folders)):\n",
        "    src_folder_chosen = list(dict_folders.values())[i]\n",
        "    src_path_chosen = os.path.join(cwd_dir, src_folder_chosen)\n",
        "    dst_folder_chosen = list(dict_folders.keys())[i]\n",
        "    # dst_path_chosen = os.path.join(dst_folder_chosen)\n",
        "\n",
        "    file_names = [f for f in os.listdir(src_path_chosen) if os.path.isfile(os.path.join(src_path_chosen, f))]\n",
        "    for file_name in file_names:\n",
        "      src = os.path.join(src_path_chosen, file_name)\n",
        "      n_random = random.uniform(0, 1)\n",
        "      if n_random < 0.65:\n",
        "        dst = os.path.join(train_dir, dst_folder_chosen, file_name)\n",
        "      elif n_random < 0.85:\n",
        "        dst = os.path.join(val_dir, dst_folder_chosen, file_name)\n",
        "      elif n_random <= 1:\n",
        "        dst = os.path.join(test_dir, dst_folder_chosen, file_name)\n",
        "      shutil.copyfile(src, dst)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKnXs1K2QGr3"
      },
      "source": [
        "#### create generators for model training ####\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 30,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 0,\n",
        "    width_shift_range = 0.0,\n",
        "    height_shift_range = 0.0,\n",
        "    horizontal_flip = False\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(cwd_dir, 'data', 'train/'),\n",
        "    target_size = (SHAPE, SHAPE),\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        ")\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    os.path.join(cwd_dir, 'data', 'validation/'),\n",
        "    target_size = (SHAPE, SHAPE),\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU8da2AnHDmR"
      },
      "source": [
        "#### a simpre model from scratch ####\n",
        "# model = models.Sequential()\n",
        "# model.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (SHAPE, SHAPE, 3)))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(512, activation = 'relu'))\n",
        "# model.add(layers.Dense(4, activation = 'softmax'))\n",
        "\n",
        "# model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.RMSprop(lr = 0.00001), metrics = ['acc'])\n",
        "\n",
        "# earlystop = EarlyStopping(monitor = 'val_loss', patience = 4, verbose = 1)\n",
        "\n",
        "# history = model.fit_generator(\n",
        "#     train_generator,\n",
        "#     epochs = 30,\n",
        "#     callbacks = earlystop,\n",
        "#     validation_data = valid_generator\n",
        "# )\n",
        "# # Save our model for inference\n",
        "# model.save(\"primo_modello.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dChStN1Yv6-c"
      },
      "source": [
        "#### transfer learning ####\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (SHAPE, SHAPE, 3))\n",
        "\n",
        "# do not train initial layers \n",
        "for layer in model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = model.output\n",
        "x = layers.AveragePooling2D(pool_size = (2, 2))(x)\n",
        "x = layers.Dense(32, activation = 'relu')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(128)(x)\n",
        "x = layers.Dense(4, activation = 'softmax', kernel_regularizer = l2(.0005))(x)\n",
        "model = Model(inputs = model.inputs, outputs = x)\n",
        "opt = optimizers.SGD(lr = 0.0001, momentum = .9)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "\n",
        "# callbacks\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', patience = 4, verbose = 1)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    os.path.join(cwd_dir, \"model-weights/xception_checkpoint.h5\"),\n",
        "    monitor = \"val_loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "# training\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [earlystop, checkpoint],\n",
        "    validation_data = valid_generator\n",
        ")\n",
        "# Save our model for inference\n",
        "model.save(os.path.join(cwd_dir, f\"model-weights/mobilenetv2_epochs_{EPOCHS}_shape_{SHAPE}.h5\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc7AmOPTb_-K"
      },
      "source": [
        "# def create_model(shape):   \r\n",
        "    \r\n",
        "#     from keras import layers\r\n",
        "#     # from keras import models\r\n",
        "#     from keras import optimizers\r\n",
        "#     # from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "#     from tensorflow.keras import Model\r\n",
        "    \r\n",
        "#     # from tensorflow.keras.initializers import glorot_uniform\r\n",
        "#     from tensorflow.keras.regularizers import l2\r\n",
        "#     # from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "#     from tensorflow.keras.applications import Xception\r\n",
        "#     model = Xception(input_shape = (shape, shape, 3), include_top = False, weights = 'imagenet')\r\n",
        "\r\n",
        "#     x = model.output\r\n",
        "#     x = layers.AveragePooling2D(pool_size = (2, 2))(x)\r\n",
        "#     x = layers.Dense(32, activation = 'relu')(x)\r\n",
        "#     x = layers.Flatten()(x)\r\n",
        "#     # spostato dopo Flatten\r\n",
        "#     x = layers.Dropout(0.1)(x)\r\n",
        "#     # a caso\r\n",
        "#     x = layers.Dense(128)(x)\r\n",
        "#     x = layers.Dense(4, activation = 'softmax', kernel_regularizer = l2(.0005))(x)\r\n",
        "#     model = Model(inputs = model.inputs, outputs = x)\r\n",
        "#     opt = optimizers.SGD(lr = 0.0001, momentum = .9)\r\n",
        "#     model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\r\n",
        "#     return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD6xEMQZ6n1c"
      },
      "source": [
        "# model2 = create_model(shape = 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDRsHesh66RR"
      },
      "source": [
        "# weights_path = \"model-weights/xception_checkpoint.h5\"\r\n",
        "# model2.load_weights(weights_path)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}